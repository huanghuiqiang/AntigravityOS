"""
synthesizer.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Antigravity OS  |  Axiom Synthesizer Agent

èŒè´£ï¼š
  1. æ‰«æ Obsidian Inboxï¼Œæ”¶é›†æ‰€æœ‰å·²æœ‰ axiom_extracted çš„ç¬”è®°
  2. å°†ç¢ç‰‡å…¬ç†æäº¤ç»™ LLMï¼Œåšï¼šå»é‡ â†’ åˆ†ç±» â†’ å‘½å â†’ æ’åº
  3. ç”Ÿæˆæ–°çš„ Axiom å€™é€‰æ¡ç›®
  4. æ›´æ–° `000 è®¤çŸ¥æ¶æ„åœ°å›¾.md`
  5. å¯é€‰ï¼šä¸ºæ¯æ¡æ–° Axiom åˆ›å»ºç‹¬ç«‹ç¬”è®°æ–‡ä»¶
  6. Telegram æ¨é€åˆæˆç»“æœæ‘˜è¦

è§¦å‘æ–¹å¼ï¼š
  - æ‰‹åŠ¨ï¼špython -m agents.axiom_synthesizer.synthesizer
  - å»ºè®®é¢‘ç‡ï¼šæ¯å‘¨ä¸€æ¬¡ï¼ˆå‘¨æ—¥æ™šï¼‰

æ³¨æ„ï¼š
  - æœ¬è„šæœ¬æ˜¯**åªè¿½åŠ **çš„â€”â€”ä¸ä¼šåˆ é™¤æˆ–ä¿®æ”¹åœ°å›¾å·²æœ‰æ¡ç›®
  - å·²å­˜åœ¨äºåœ°å›¾ä¸­çš„ Axiom æ ‡é¢˜ä¼šè¢«è‡ªåŠ¨è·³è¿‡ï¼ˆå¹‚ç­‰ï¼‰
"""

import re
import json
import argparse
import httpx
from pathlib import Path
from datetime import datetime

from agos.config import (
    openrouter_api_key, vault_path, inbox_folder,
    min_score_threshold, model_synthesizer, synth_max_batch,
)
from agos.notify import send_message
from agos.frontmatter import parse_frontmatter

from skills.obsidian_bridge.bridge import (
    get_vault, list_notes, read_note, write_note, append_note,
    update_frontmatter,
)

# â”€â”€ é…ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MAP_FILE = "000 è®¤çŸ¥æ¶æ„åœ°å›¾.md"
INBOX_FOLDER = inbox_folder()
MIN_AXIOM_SCORE = min_score_threshold()
MAX_AXIOMS_BATCH = synth_max_batch()


# â”€â”€ Step 1: æ”¶é›†ç¢ç‰‡å…¬ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _warn(scope: str, detail: str, err: Exception | None = None):
    if err is None:
        print(f"  âš ï¸ [{scope}] {detail}")
    else:
        print(f"  âš ï¸ [{scope}] {detail}: {err}")



def collect_raw_axioms() -> list[dict]:
    """
    æ‰«æ Inbox ä¸­æ‰€æœ‰ BouncerDump / WebClip ç¬”è®°ï¼Œ
    æå– [!abstract] callout ä¸­çš„å…¬ç†æ–‡æœ¬ã€‚
    è·³è¿‡å·²æ‰“æ ‡ synthesized: true çš„ç¬”è®°ã€‚
    """
    vault = get_vault()
    inbox_dir = vault / INBOX_FOLDER
    raw = []
    seen_axioms: set[str] = set()

    def _try_extract(f: Path):
        try:
            content = f.read_text(encoding="utf-8")
            fm, body = parse_frontmatter(content)

            # å¢é‡é€»è¾‘ï¼šè·³è¿‡å·²åˆæˆç¬”è®°
            if fm.get("synthesized") is True:
                return

            tags = fm.get("tags", [])
            if isinstance(tags, str):
                tags = [tags]
            if not any(t in tags for t in ["BouncerDump", "WebClip", "PDFIngested"]):
                return
            score = float(fm.get("score", 0))
            if score < MIN_AXIOM_SCORE:
                return

            # åŒ¹é…å®é™…æ ¼å¼
            axiom = ""
            m = re.search(
                r">\s*\[!abstract\][^\n]*\n>\s*(.+?)(?:\n|$)",
                body
            )
            if m:
                axiom = m.group(1).strip()

            if not axiom:
                m2 = re.search(r"\[!abstract\].*?\n>\s*(.+?)(?:\n|$)", content)
                if m2:
                    axiom = m2.group(1).strip()

            if not axiom or axiom in ("å¾…æç‚¼", ""):
                return

            # å»é‡
            key = axiom[:80]
            if key in seen_axioms:
                return
            seen_axioms.add(key)

            raw.append({
                "axiom": axiom,
                "score": score,
                "source": str(fm.get("source", "")),
                "title": str(fm.get("title", f.stem)),
                "path": str(f)
            })
        except Exception as e:
            _warn("synthesizer/collect", f"è§£æç¬”è®°å¤±è´¥: {f}", e)

    def _scan_dir(d: Path):
        for f in d.iterdir():
            if f.is_dir():
                _scan_dir(f)
            elif f.suffix == ".md":
                _try_extract(f)

    if inbox_dir.exists():
        _scan_dir(inbox_dir)

    print(f"  ğŸ“š å…±æ”¶é›†åˆ° {len(raw)} æ¡æ–°å…¬ç†ç¢ç‰‡ï¼ˆscore â‰¥ {MIN_AXIOM_SCORE}ï¼Œå¢é‡æ‰«æï¼‰")
    return raw


def mark_as_synthesized(paths: list[str]):
    """å°†å·²æå–å…¬ç†çš„ç¬”è®°æ‰“ä¸Š synthesized: true æ ‡è®°ã€‚"""
    print(f"  æ ‡è®° {len(paths)} æ¡ç¬”è®°ä¸ºå·²åˆæˆ...")
    for p in paths:
        update_frontmatter(p, {"synthesized": True})


# â”€â”€ Step 2: è¯»å–ç°æœ‰åœ°å›¾ï¼ˆé˜²æ­¢é‡å¤è¿½åŠ ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def read_map() -> str:
    map_path = get_vault() / MAP_FILE
    if map_path.exists():
        return map_path.read_text(encoding="utf-8")
    return ""


def extract_existing_axiom_titles(map_content: str) -> set[str]:
    return set(re.findall(r"\[\[Axiom - ([^\]]+)\]\]", map_content))


# â”€â”€ Step 3: LLM åˆæˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SYNTHESIS_PROMPT = """
ä½ æ˜¯ Antigravity OS çš„"è®¤çŸ¥è’¸é¦å¸ˆ"ã€‚ä½ çš„ä»»åŠ¡æ˜¯å¯¹æ”¶é›†åˆ°çš„ç¢ç‰‡å…¬ç†åšï¼š

1. **è¯­ä¹‰å»é‡**ï¼šåˆå¹¶è¡¨è¾¾ç›¸åŒåº•å±‚è§„å¾‹çš„å…¬ç†
2. **æå‡æŠ½è±¡å±‚**ï¼šå°†è¿‡äºå…·ä½“çš„æè¿°å‡åä¸ºå¯å¤ç”¨çš„"ç¬¬ä¸€æ€§åŸç†"
3. **å‘½åè§„èŒƒåŒ–**ï¼šæ¯æ¡å…¬ç†é‡‡ç”¨æ ¼å¼ `å…¬ç†åç§° (å‰¯æ ‡é¢˜/å…³é”®è¯)`
4. **æ’åº**ï¼šæŒ‰"è®¤çŸ¥å¯†åº¦"ä»é«˜åˆ°ä½æ’åˆ—

è¾“å‡ºæ ¼å¼å¿…é¡»æ˜¯åˆæ³•çš„ JSON æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
{{"name": "ç®€æ´çš„è‹±æ–‡/ä¸­æ–‡å…¬ç†åç§° (å…³é”®è¯)", "meaning": "ä¸€å¥è¯ï¼šè¿™æ¡å…¬ç†çš„åº•å±‚è§„å¾‹æ˜¯ä»€ä¹ˆ", "sources": ["æ¥æºæ ‡é¢˜1"], "is_new": true}}

é‡è¦çº¦æŸï¼š
- åªè¿”å› JSON æ•°ç»„ï¼Œä¸è¦ä»»ä½• Markdown åŒ…è£¹
- æœ€å¤šè¾“å‡º 8 æ¡ï¼ˆä¼˜ä¸­é€‰ä¼˜ï¼‰
- å¦‚æœç¢ç‰‡ä¸­æ²¡æœ‰ä»»ä½•å€¼å¾—æç‚¼çš„æ–°å…¬ç†ï¼Œè¿”å›ç©ºæ•°ç»„ []

ä»¥ä¸‹æ˜¯å·²å­˜åœ¨äºè®¤çŸ¥åœ°å›¾ä¸­çš„å…¬ç†ï¼ˆè¯·å‹¿é‡å¤ï¼‰ï¼š
{existing}

ä»¥ä¸‹æ˜¯æœ¬æ¬¡æ”¶é›†åˆ°çš„ç¢ç‰‡å…¬ç†ï¼ˆJSON æ ¼å¼ï¼‰ï¼š
{raw_axioms}
"""


def synthesize_with_llm(raw_axioms: list[dict], existing_titles: set[str]) -> tuple[list[dict], list[str]]:
    api_key = openrouter_api_key()
    if not api_key:
        print("  âŒ æœªæ‰¾åˆ° API Key")
        return [], []

    unique_axioms = []
    seen = set()
    for a in raw_axioms:
        key = a["axiom"][:60]
        if key not in seen:
            seen.add(key)
            unique_axioms.append(a)

    batch = unique_axioms[:MAX_AXIOMS_BATCH]
    processed_paths = [a["path"] for a in batch if "path" in a]

    model = model_synthesizer()
    print(f"  ğŸ§  æäº¤ {len(batch)} æ¡ç¢ç‰‡ç»™ {model} åˆæˆ...")

    llm_batch = [{"axiom": a["axiom"], "title": a["title"]} for a in batch]

    prompt = SYNTHESIS_PROMPT.format(
        existing="\n".join(f"- {t}" for t in sorted(existing_titles)) or "(æ— )",
        raw_axioms=json.dumps(llm_batch, ensure_ascii=False, indent=2),
    )

    try:
        with httpx.Client(timeout=60.0) as client:
            resp = client.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json",
                    "HTTP-Referer": "https://github.com/huanghuiqiang/AntigravityOS",
                    "X-Title": "Antigravity Axiom Synthesizer",
                },
                json={
                    "model": model,
                    "messages": [{"role": "user", "content": prompt}],
                    "response_format": {"type": "json_object"},
                },
            )

        if resp.status_code != 200:
            print(f"  âŒ LLM å“åº”å¼‚å¸¸: HTTP {resp.status_code}")
            return [], []

        raw_out = resp.json()["choices"][0]["message"]["content"]
        clean = raw_out.strip().lstrip("```json").lstrip("```").rstrip("```").strip()

        parsed = json.loads(clean)
        if isinstance(parsed, dict):
            for v in parsed.values():
                if isinstance(v, list):
                    parsed = v
                    break
            else:
                parsed = []

        print(f"  âœ… åˆæˆå‡º {len(parsed)} æ¡å€™é€‰å…¬ç†")
        return parsed, processed_paths

    except Exception as e:
        print(f"  âŒ LLM åˆæˆå‡ºé”™: {e}")
        return [], []


# â”€â”€ Step 4: æ›´æ–°è®¤çŸ¥åœ°å›¾ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def update_map(synthesized: list[dict], dry_run: bool = False) -> list[str]:
    if not synthesized:
        return []

    map_path = get_vault() / MAP_FILE
    map_content = read_map()
    existing = extract_existing_axiom_titles(map_content)

    new_ones = [
        a for a in synthesized
        if a.get("is_new", True)
        and not any(
            a["name"].lower() in t.lower() or t.lower() in a["name"].lower()
            for t in existing
        )
    ]

    if not new_ones:
        print("  â„¹ï¸  æ‰€æœ‰åˆæˆå…¬ç†å·²å­˜åœ¨äºåœ°å›¾ï¼Œæ— éœ€è¿½åŠ ")
        return []

    today = datetime.now().strftime("%Y-%m-%d")
    num_start = len(re.findall(r"^\d+\.\s+\*\*", map_content, re.MULTILINE)) + 1
    new_lines = [
        f"\n\n---\n\n## ğŸ†• Synthesizer è¿½åŠ  ({today})\n"
        f"> ç”± Axiom Synthesizer ä» Bouncer è¾“å‡ºä¸­è‡ªåŠ¨æç‚¼\n"
    ]

    written = []
    for i, axiom in enumerate(new_ones, num_start):
        name = axiom.get("name", "æœªå‘½åå…¬ç†")
        meaning = axiom.get("meaning", "")
        sources = axiom.get("sources", [])
        src_str = "ã€".join(sources[:3]) if sources else ""

        entry = (
            f"{i}. **{name}**: [[Axiom - {name}]]\n"
            f"    *   *Meaning*: {meaning}\n"
        )
        if src_str:
            entry += f"    *   *æºè‡ª*: {src_str}\n"

        new_lines.append(entry)
        written.append(name)

    append_block = "\n".join(new_lines)

    if dry_run:
        print("\n[DRY RUN] å°†è¿½åŠ ä»¥ä¸‹å†…å®¹åˆ°è®¤çŸ¥åœ°å›¾ï¼š")
        print(append_block)
        return written

    with map_path.open("a", encoding="utf-8") as f:
        f.write(append_block)

    print(f"  âœ… å·²è¿½åŠ  {len(written)} æ¡æ–°å…¬ç†åˆ°è®¤çŸ¥åœ°å›¾")
    return written


# â”€â”€ Step 5: ä¸ºæ¯æ¡æ–° Axiom åˆ›å»ºç‹¬ç«‹ç¬”è®° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def create_axiom_notes(synthesized: list[dict], dry_run: bool = False) -> list[str]:
    created = []
    for axiom in synthesized:
        name = axiom.get("name", "")
        meaning = axiom.get("meaning", "")
        sources = axiom.get("sources", [])
        if not name:
            continue

        safe_name = re.sub(r'[\\/*?:"<>|]', "", name)[:80].strip()
        filename = f"Axiom - {safe_name}.md"
        note_path = get_vault() / filename

        if note_path.exists():
            continue

        today = datetime.now().strftime("%Y-%m-%d")
        src_links = "\n".join(f"- {s}" for s in sources) if sources else "- (è‡ªåŠ¨åˆæˆ)"

        content = f"""---
tags:
  - Axiom
  - AutoSynthesized
created: "{today}"
---

# {name}

> [!abstract] æ ¸å¿ƒå…¬ç†
> {meaning}

## æ¨å¯¼ä¸èƒŒæ™¯

æœ¬æ¡å…¬ç†ç”± **Axiom Synthesizer** ä»ä»¥ä¸‹ä¿¡æ¯æºä¸­è‡ªåŠ¨æç‚¼ï¼š

{src_links}

## ä¸è®¤çŸ¥æ¶æ„çš„å…³è”

- [[000 è®¤çŸ¥æ¶æ„åœ°å›¾]]

---
*ç”± AntigravityOS Axiom Synthesizer è‡ªåŠ¨ç”Ÿæˆ Â· {today}*
"""
        if not dry_run:
            note_path.write_text(content, encoding="utf-8")
            print(f"  ğŸ“„ åˆ›å»º Axiom ç¬”è®°: {filename}")
        else:
            print(f"  [DRY RUN] å°†åˆ›å»º: {filename}")

        created.append(str(note_path))

    return created


# â”€â”€ Step 6: Telegram é€šçŸ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def notify(written: list[str], created_notes: list[str], total_raw: int, dry_run: bool):
    if dry_run:
        return

    if not written:
        text = (
            "ğŸ§¬ <b>Axiom Synthesizer è¿è¡Œå®Œæ¯•</b>\n\n"
            f"ğŸ“š å·²åˆ†æ <b>{total_raw}</b> æ¡å…¬ç†ç¢ç‰‡\n"
            "â„¹ï¸ æ— æ–°å…¬ç†éœ€è¦è¿½åŠ ï¼ˆå‡å·²å­˜åœ¨äºè®¤çŸ¥åœ°å›¾ï¼‰"
        )
    else:
        lines = [
            "ğŸ§¬ <b>Axiom Synthesizer â€” æ–°å…¬ç†æç‚¼å®Œæˆ</b>",
            f"ğŸ“š åˆ†æ <b>{total_raw}</b> æ¡ç¢ç‰‡ â†’ æç‚¼ <b>{len(written)}</b> æ¡æ–°å…¬ç†\n",
        ]
        for name in written:
            lines.append(f"âœ¨ <b>{name}</b>")
        lines.append(f"\nğŸ“ å·²è¿½åŠ åˆ° [[000 è®¤çŸ¥æ¶æ„åœ°å›¾]]")
        if created_notes:
            lines.append(f"ğŸ“‚ åˆ›å»ºç‹¬ç«‹ç¬”è®° {len(created_notes)} ä¸ª")
        text = "\n".join(lines)

    send_message(text)


# â”€â”€ ä¸»æµç¨‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main(dry_run: bool = False, create_notes: bool = True):
    print("=" * 55)
    print("ğŸ§¬ [Axiom Synthesizer] å¯åŠ¨...")
    print(f"   Vault:    {get_vault()}")
    print(f"   åœ°å›¾:     {MAP_FILE}")
    print(f"   Dry Run:  {dry_run}")
    print("=" * 55)

    # 1. é‡‡é›†ç¢ç‰‡
    raw_axioms = collect_raw_axioms()
    if not raw_axioms:
        print("\nâš ï¸  æœªæ”¶é›†åˆ°æœ‰æ•ˆå…¬ç†ç¢ç‰‡ï¼Œé€€å‡ºã€‚")
        return

    # 2. è¯»ç°æœ‰åœ°å›¾ï¼Œé˜²é‡å¤
    map_content = read_map()
    existing_titles = extract_existing_axiom_titles(map_content)
    print(f"  ğŸ—ºï¸  è®¤çŸ¥åœ°å›¾å·²æœ‰ {len(existing_titles)} æ¡å…¬ç†")

    # 3. LLM åˆæˆ
    synthesized, processed_paths = synthesize_with_llm(raw_axioms, existing_titles)
    if not synthesized:
        print("\nâš ï¸  LLM æœªåˆæˆå‡ºæ–°å…¬ç†ã€‚")
        if not dry_run and processed_paths:
            mark_as_synthesized(processed_paths)
        notify([], [], len(raw_axioms), dry_run)
        return

    # 4. æ›´æ–°åœ°å›¾
    written = update_map(synthesized, dry_run=dry_run)

    # 5. åˆ›å»ºç‹¬ç«‹ç¬”è®°ï¼ˆå¯é€‰ï¼‰
    created_notes = []
    if create_notes and written:
        created_notes = create_axiom_notes(synthesized, dry_run=dry_run)

    # 6. æ ‡è®°ä¸ºå·²åˆæˆï¼ˆå¢é‡å…³é”®ï¼‰
    if not dry_run and processed_paths:
        mark_as_synthesized(processed_paths)

    # 7. æ¨é€é€šçŸ¥
    notify(written, created_notes, len(raw_axioms), dry_run)

    # 8. æ±‡æ€»è¾“å‡º
    print("\n" + "=" * 55)
    print(f"âœ… åˆæˆå®Œæˆ")
    print(f"   åŸå§‹ç¢ç‰‡:  {len(raw_axioms)} æ¡")
    print(f"   æ–°å¢å…¬ç†:  {len(written)} æ¡")
    print(f"   ç‹¬ç«‹ç¬”è®°:  {len(created_notes)} ä¸ª")
    print("=" * 55)
    for name in written:
        print(f"   âœ¨ {name}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Antigravity Axiom Synthesizer")
    parser.add_argument("--dry-run", action="store_true", help="åªåˆ†æï¼Œä¸å†™å…¥")
    parser.add_argument("--no-notes", action="store_true", help="ä¸åˆ›å»ºç‹¬ç«‹ Axiom ç¬”è®°")
    parser.add_argument("--min-score", type=float, default=MIN_AXIOM_SCORE)
    parser.add_argument("--max-batch", type=int, default=MAX_AXIOMS_BATCH)
    args = parser.parse_args()

    MIN_AXIOM_SCORE = args.min_score
    MAX_AXIOMS_BATCH = args.max_batch

    main(dry_run=args.dry_run, create_notes=not args.no_notes)
