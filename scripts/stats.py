"""
stats.py â”€â”€ Antigravity OS æ•°æ®æ”¶é›†å…±äº«å±‚
A/B ä¸¤ç§ä»ªè¡¨ç›˜éƒ½ä»è¿™é‡Œè¯»æ•°æ®ï¼Œä¿æŒé€»è¾‘ç»Ÿä¸€ã€‚
"""

import re
import json
import sys
from pathlib import Path
from datetime import datetime, timedelta
from collections import defaultdict, Counter
from dataclasses import dataclass, field
from typing import Optional

from agos.config import (
    project_root,
    log_dir,
    vault_path,
    inbox_folder,
    inbox_path,
    bouncer_log_file,
    inbox_processor_log_file,
)
from agos.frontmatter import parse_frontmatter

# â”€â”€ è·¯å¾„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROOT = project_root()
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

INBOX_FOLDER = inbox_folder()


# â”€â”€ æ•°æ®ç»“æ„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class NoteRecord:
    filename:     str
    status:       str        # pending / done / error / (unknown)
    score:        float
    source:       str
    title:        str
    created:      str        # YYYY-MM-DD
    processed_at: str        # YYYY-MM-DD HH:MM  or ""
    error_type:   str
    tags:         list[str]
    is_clip:      bool       # True = WebClip, False = Bouncer

@dataclass
class CronRun:
    agent:   str             # bouncer / inbox_processor
    time:    datetime
    scanned: int = 0
    golden:  int = 0
    success: bool = True

@dataclass
class StatsReport:
    # â”€â”€ Inbox çŠ¶æ€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    notes: list[NoteRecord] = field(default_factory=list)

    # â”€â”€ èšåˆæŒ‡æ ‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    total:       int = 0
    pending:     int = 0
    done:        int = 0
    error:       int = 0
    error_types: dict = field(default_factory=dict)
    clips_today: int = 0

    score_dist:  dict = field(default_factory=dict)
    daily_inbox: dict = field(default_factory=dict)
    daily_done:  dict = field(default_factory=dict)

    # â”€â”€ Cron å†å² â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    last_bouncer_run:   Optional[datetime] = None
    last_inbox_run:     Optional[datetime] = None
    bouncer_idle_hours: float = 0.0
    inbox_idle_hours:   float = 0.0
    bouncer_7day:       list = field(default_factory=list)
    throughput_7day:    list = field(default_factory=list)

    # â”€â”€ ç³»ç»Ÿå¥åº· â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    health_score:   float = 0.0
    bottleneck:     str   = ""
    generated_at:   str   = ""

    # â”€â”€ å®¡è®¡æ•°æ® (Knowledge Auditor) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    orphan_axioms:  list[str] = field(default_factory=list)
    backlog_issues: list[dict] = field(default_factory=list)
    meta_issues:    list[str] = field(default_factory=list)


# â”€â”€ å†…éƒ¨å·¥å…· â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _warn(scope: str, detail: str, err: Exception | None = None):
    payload = {
        "ts": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "level": "WARN",
        "scope": scope,
        "detail": detail,
    }
    if err is not None:
        payload["error"] = str(err)
        payload["error_type"] = type(err).__name__
    print(json.dumps(payload, ensure_ascii=False))


def _pick_latest_existing(paths: list[Path]) -> Path | None:
    existing = [p for p in paths if p.exists()]
    if not existing:
        return None
    return max(existing, key=lambda p: p.stat().st_mtime)


def _bouncer_log_candidates() -> list[Path]:
    # å…¼å®¹å†å²å‘½åï¼šcognitive_bouncer.log
    return [bouncer_log_file(), log_dir() / "cognitive_bouncer.log"]


def _inbox_log_candidates() -> list[Path]:
    return [inbox_processor_log_file()]


def _parse_bouncer_log() -> list[CronRun]:
    """ä» bouncer.log æå–å†å²è¿è¡Œè®°å½•ã€‚"""
    runs = []
    log_path = _pick_latest_existing(_bouncer_log_candidates())
    if log_path is None:
        return runs

    content = log_path.read_text(encoding="utf-8", errors="ignore")
    scanned_re = re.compile(r"(?:æœ¬æ¬¡)?å…±å®¡æŸ¥\s*(\d+)\s*ç¯‡")
    golden_re  = re.compile(r"é«˜è®¤çŸ¥å¯†åº¦æ–‡ç« :\s*(\d+)")

    try:
        mtime = datetime.fromtimestamp(log_path.stat().st_mtime)
        scanned_match = scanned_re.search(content)
        golden_match = golden_re.search(content)
        scanned = int(scanned_match.group(1)) if scanned_match else 0
        golden = int(golden_match.group(1)) if golden_match else 0
        runs.append(CronRun(agent="bouncer", time=mtime, scanned=scanned, golden=golden))
    except Exception as e:
        _warn("stats/bouncer_log", f"è§£ææ—¥å¿—å¤±è´¥: {log_path}", e)
    return runs


def _parse_inbox_log() -> list[CronRun]:
    runs = []
    log_path = _pick_latest_existing(_inbox_log_candidates())
    if log_path is None:
        return runs
    try:
        mtime = datetime.fromtimestamp(log_path.stat().st_mtime)
        runs.append(CronRun(agent="inbox_processor", time=mtime))
    except Exception as e:
        _warn("stats/inbox_log", f"è§£ææ—¥å¿—å¤±è´¥: {log_path}", e)
    return runs


def _load_auditor():
    from agents.knowledge_auditor.auditor import Auditor
    return Auditor


# â”€â”€ ä¸»æ”¶é›†å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def collect() -> StatsReport:
    report = StatsReport(generated_at=datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    today_str = datetime.now().strftime("%Y-%m-%d")
    vault = vault_path()
    inbox_dir = inbox_path()

    # â”€â”€ 1. æ‰«æ Inbox ç¬”è®° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    notes: list[NoteRecord] = []

    def _scan_dir(d: Path):
        for f in d.iterdir():
            if f.is_dir():
                _scan_dir(f)
            elif f.suffix == ".md":
                try:
                    content = f.read_text(encoding="utf-8", errors="ignore")
                    fm, _ = parse_frontmatter(content)
                    if not fm:
                        _warn("stats/scan_note", f"frontmatter ç¼ºå¤±ï¼Œè·³è¿‡: {f}")
                        continue

                    tags = fm.get("tags", [])
                    if isinstance(tags, str):
                        tags = [tags]
                    if not any(t in tags for t in ["BouncerDump", "WebClip", "PDFIngested"]):
                        continue

                    notes.append(NoteRecord(
                        filename=f.name,
                        status=str(fm.get("status", "unknown")),
                        score=float(fm.get("score", 0)),
                        source=str(fm.get("source", "")),
                        title=str(fm.get("title", f.stem)),
                        created=str(fm.get("created", "")),
                        processed_at=str(fm.get("processed_at", "")),
                        error_type=str(fm.get("error_type", "")),
                        tags=tags,
                        is_clip="WebClip" in tags,
                    ))
                except Exception as e:
                    _warn("stats/scan_note", f"è§£æå¤±è´¥: {f}", e)

    if inbox_dir.exists():
        _scan_dir(inbox_dir)

    report.notes = notes
    report.total = len(notes)

    # â”€â”€ 2. çŠ¶æ€ç»Ÿè®¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    status_counter = Counter(n.status for n in notes)
    report.pending = status_counter.get("pending", 0)
    report.done = status_counter.get("done", 0)
    report.error = status_counter.get("error", 0)
    err_counter = Counter(
        (n.error_type if n.error_type else "unknown_error")
        for n in notes
        if n.status == "error"
    )
    report.error_types = dict(err_counter)
    report.clips_today = sum(1 for n in notes if n.is_clip and n.created == today_str)

    # â”€â”€ 3. åˆ†æ•°åˆ†å¸ƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    buckets = {"9-10": 0, "8-9": 0, "7-8": 0, "<7": 0}
    for n in notes:
        s = n.score
        if s >= 9:    buckets["9-10"] += 1
        elif s >= 8:  buckets["8-9"] += 1
        elif s >= 7:  buckets["7-8"] += 1
        else:         buckets["<7"] += 1
    report.score_dist = buckets

    # â”€â”€ 4. æ¯æ—¥å…¥åº“è¶‹åŠ¿ï¼ˆæœ€è¿‘ 7 å¤©ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    days7 = [(datetime.now() - timedelta(days=i)).strftime("%Y-%m-%d") for i in range(6, -1, -1)]
    daily_inbox = defaultdict(int)
    daily_done = defaultdict(int)
    for n in notes:
        if n.created in days7:
            daily_inbox[n.created] += 1
        if n.processed_at and n.processed_at[:10] in days7:
            daily_done[n.processed_at[:10]] += 1

    report.bouncer_7day = [daily_inbox[d] for d in days7]
    report.throughput_7day = [daily_done[d] for d in days7]

    # â”€â”€ 5. Cron æœ€åè¿è¡Œæ—¶é—´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    bouncer_runs = _parse_bouncer_log()
    inbox_runs = _parse_inbox_log()
    if bouncer_runs:
        report.last_bouncer_run = bouncer_runs[-1].time
        report.bouncer_idle_hours = (
            datetime.now() - report.last_bouncer_run
        ).total_seconds() / 3600
    if inbox_runs:
        report.last_inbox_run = inbox_runs[-1].time
        report.inbox_idle_hours = (
            datetime.now() - report.last_inbox_run
        ).total_seconds() / 3600

    # â”€â”€ 6. è¿è¡Œ Knowledge Auditor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    try:
        Auditor = _load_auditor()
        auditor = Auditor(vault)
        report.orphan_axioms = auditor.audit_orphans()
        report.backlog_issues = auditor.audit_backlog()
        report.meta_issues = auditor.audit_metadata()
    except Exception as e:
        _warn("stats/auditor", "Auditor integration failed", e)

    # â”€â”€ 7. ç³»ç»Ÿå¥åº·è¯„åˆ† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    health = 100.0
    bottlenecks = []

    if report.total > 0:
        err_rate = report.error / report.total
        if err_rate > 0.1:
            health -= 20
            bottlenecks.append(f"âŒ Error ç‡ {err_rate:.0%}")

    if report.pending > 20:
        health -= 15
        bottlenecks.append(f"â³ Pending ç§¯å‹ {report.pending} æ¡")

    if report.orphan_axioms:
        penalty = min(15, len(report.orphan_axioms) * 2)
        health -= penalty
        bottlenecks.append(f"ğŸ•¸ çŸ¥è¯†å­¤å²› ({len(report.orphan_axioms)})")

    if report.last_bouncer_run:
        idle_h = (datetime.now() - report.last_bouncer_run).total_seconds() / 3600
        if idle_h > 26:
            health -= 20
            bottlenecks.append(f"ğŸ”‡ Bouncer å·² {idle_h:.0f}h æœªè¿è¡Œ")

    report.health_score = max(0.0, health)
    report.bottleneck = bottlenecks[0] if bottlenecks else "âœ… ç³»ç»Ÿè¿è¡Œæ­£å¸¸"

    return report


# â”€â”€ CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    report = collect()
    print(json.dumps(report.__dict__, indent=4, default=str))
