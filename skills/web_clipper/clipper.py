"""
clipper.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Antigravity OS  |  Web Clipper Skill

èŒè´£ï¼š
  æ¥å—ä¸€ä¸ª URL â†’ æå–æ­£æ–‡ â†’ Bouncer LLM è¯„åˆ† â†’ å†™å…¥ Obsidian Inbox
"""

import re
import json
import argparse
import httpx
from pathlib import Path
from datetime import datetime
from typing import Optional

from agos.config import (
    openrouter_api_key, vault_path, inbox_folder,
    min_score_threshold, model_bouncer,
)
from agos.notify import send_message

from skills.obsidian_bridge.bridge import write_note

# â”€â”€ é…ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MIN_SCORE_INBOX = min_score_threshold()
OPENROUTER_KEY  = openrouter_api_key()
MODEL           = model_bouncer()
INBOX_DIR       = vault_path() / inbox_folder()

# â”€â”€ æ­£æ–‡æå– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_content(url: str) -> dict:
    """
    ç”¨ trafilatura æå–é«˜è´¨é‡æ­£æ–‡ã€‚
    å›é€€é“¾ï¼štrafilatura â†’ BeautifulSoup <p> â†’ ç©ºå­—ç¬¦ä¸²
    """
    # ä¼˜å…ˆç”¨ trafilatura
    try:
        import trafilatura
        downloaded = trafilatura.fetch_url(url)
        if downloaded:
            result = trafilatura.extract(
                downloaded,
                include_comments=False,
                include_tables=False,
                output_format="json",
            )
            if result:
                data = json.loads(result)
                return {
                    "title":  data.get("title", ""),
                    "text":   (data.get("text", "") or "")[:6000],
                    "author": data.get("author", ""),
                    "date":   data.get("date", ""),
                }
    except Exception as e:
        print(f"  [trafilatura å¤±è´¥ï¼Œé™çº§]: {e}")

    # å›é€€ï¼šBeautifulSoup æŠ“ <p> æ®µè½
    try:
        from bs4 import BeautifulSoup
        headers = {"User-Agent": "Mozilla/5.0 (compatible; AntigravityClipper/1.0)"}
        with httpx.Client(timeout=12.0, follow_redirects=True) as client:
            resp = client.get(url, headers=headers)
            if resp.status_code == 200:
                soup  = BeautifulSoup(resp.content, "html.parser")
                title = soup.title.string if soup.title else ""
                paras = " ".join(p.get_text() for p in soup.find_all("p"))
                return {"title": title, "text": paras[:6000], "author": "", "date": ""}
    except Exception as e:
        print(f"  [BeautifulSoup å›é€€å¤±è´¥]: {e}")

    return {"title": "", "text": "", "author": "", "date": ""}


# â”€â”€ LLM è¯„åˆ† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªåå« 'Antigravity Bouncer' çš„è®¤çŸ¥å®ˆé—¨å‘˜ã€‚ä½ çš„å”¯ä¸€èŒè´£æ˜¯å¯¹æŠ—ä¿¡æ¯ç†µå¢ã€‚
è¯·é˜…è¯»æäº¤çš„æ–‡ç« æ‘˜è¦å’Œç‰‡æ®µï¼Œå¹¶è¯„ä¼°å…¶"è®¤çŸ¥æ‘©æ“¦ï¼ˆFrictionï¼‰"å’Œ"ç³»ç»Ÿ2æ·±åº¦ï¼ˆSystem 2 Depthï¼‰"ã€‚

ã€é«˜åˆ†æ ‡å‡† (8.0-10.0)ã€‘ï¼š
1. å…·æœ‰å¼ºçƒˆçš„"åå…±è¯†"æˆ–é¢ è¦†ä¼ ç»Ÿçš„æå®¢/å·¥ç¨‹è§†è§’ã€‚
2. èƒ½æç‚¼å‡ºå…·æœ‰å¤åˆ©ä»·å€¼çš„"å…¬ç†ï¼ˆAxiomï¼‰"æˆ–æ¶æ„æ€æƒ³ã€‚
3. èƒ½å¤ŸæŒ‡å¯¼ç¨‹åºå‘˜å»"é€ æœ¬èƒ½"ï¼Œè€Œä¸æ˜¯"æ‰¾è½®å­"ã€‚

ã€ä½åˆ†åƒåœ¾ (0.0-7.9)ã€‘ï¼š
1. è¹­çƒ­ç‚¹çš„æ°´æ–‡ã€æƒ…ç»ªå®£æ³„ã€‚
2. æ— è„‘æ¬è¿çš„æ–°é—»é€šç¨¿ã€å¸¸è¯†åºŸè¯ã€"å¦‚ä½•å®‰è£…Python"ç­‰åŸºç¡€æ•™ç¨‹ã€‚
3. è½¯å¹¿æˆ–æ ‡é¢˜å…šã€‚

è¯·ä¸¥æ ¼è¿”å›åˆæ³•çš„ JSON å¯¹è±¡ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
{"score": æ•°å­—(0-10), "reason": "æç®€çš„ä¸€å¥è¯è§£é‡Šæ˜¯å¦æœ‰æŠ€æœ¯ä»·å€¼", "axiom_extracted": "æå–çš„åº•å±‚å…¬ç†(ä½åˆ†å¯ç•™ç©º)"}
ç¡®ä¿é™¤äº†ä¸Šè¿° JSON å¤–ä¸è¾“å‡ºä»»ä½•å¤šä½™çš„ Markdown æ ‡è®°æˆ–å…¶ä»–æ–‡æœ¬ã€‚
"""


def evaluate(title: str, text: str) -> Optional[dict]:
    """è°ƒç”¨ LLM è¯„åˆ†ã€‚"""
    if not OPENROUTER_KEY:
        print("  âŒ æœªæ‰¾åˆ° API Keyï¼Œè¯·é…ç½® .env")
        return None

    eval_text = f"Title: {title}\nBody Snippet:\n{text[:3000]}"

    try:
        with httpx.Client(timeout=30.0) as client:
            resp = client.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers={
                    "Authorization":  f"Bearer {OPENROUTER_KEY}",
                    "Content-Type":   "application/json",
                    "HTTP-Referer":   "https://github.com/huanghuiqiang/AntigravityOS",
                    "X-Title":        "Antigravity Web Clipper",
                },
                json={
                    "model":    MODEL,
                    "messages": [
                        {"role": "system", "content": SYSTEM_PROMPT},
                        {"role": "user",   "content": eval_text},
                    ],
                    "response_format": {"type": "json_object"},
                },
            )

        if resp.status_code != 200:
            print(f"  âŒ LLM å“åº”å¼‚å¸¸: HTTP {resp.status_code}")
            return None

        raw = resp.json()["choices"][0]["message"]["content"]
        clean = raw.strip().lstrip("```json").lstrip("```").rstrip("```").strip()
        return json.loads(clean)

    except Exception as e:
        print(f"  âŒ LLM è¯„åˆ†å‡ºé”™: {e}")
        return None


# â”€â”€ å†™å…¥ Obsidian Inbox â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def write_to_inbox(
    url: str,
    title: str,
    score: float,
    reason: str,
    axiom: str,
    author: str = "",
    date: str = "",
) -> str:
    """å°†é«˜åˆ†æ–‡ç« å†™å…¥ Obsidian 00_Inboxã€‚"""
    safe_title = re.sub(r'[\\/*?:"<>|]', "", title)[:60].strip() or "Untitled"
    filename   = f"Clip - {safe_title}.md"
    filepath   = INBOX_DIR / filename

    today = datetime.now().strftime("%Y-%m-%d")
    meta_author = f"\n**ä½œè€…**: {author}" if author else ""
    meta_date   = f"\n**å‘å¸ƒæ—¥æœŸ**: {date}" if date else ""

    content = f"""---
tags:
  - WebClip
score: {score}
status: pending
source: "{url}"
title: "{title.replace('"', "'")}"
created: "{today}"
---

# {title}

**æ¥æºé“¾æ¥**: [{url}]({url}){meta_author}{meta_date}
**è®¤çŸ¥å¾—åˆ†**: {score}

> [!abstract] æ ¸å¿ƒå…¬ç† (Axiom)
> {axiom if axiom else "å¾…æç‚¼"}

> [!info] å®ˆé—¨å‘˜åˆ¤å†³ç†ç”± (Reason)
> {reason}
"""
    INBOX_DIR.mkdir(parents=True, exist_ok=True)
    filepath.write_text(content, encoding="utf-8")
    print(f"  ğŸ“¥ å·²å†™å…¥ Inbox: {filename}")
    return str(filepath)


# â”€â”€ Telegram é€šçŸ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def notify(url: str, title: str, score: float, reason: str, axiom: str, written: bool):
    """æ¨é€è¯„åˆ†ç»“æœåˆ° Telegramã€‚"""
    if score >= 9.5:   medal = "ğŸ’"
    elif score >= 9.0: medal = "ğŸ†"
    elif score >= 8.5: medal = "ğŸ¥‡"
    elif score >= 8.0: medal = "â­ï¸"
    else:              medal = "ğŸ—‘ï¸"

    inbox_line = f"ğŸ“¥ å·²å†™å…¥ Obsidian Inbox" if written else "âŒ ä½åˆ†ï¼Œæœªå…¥åº“"

    text = (
        f"âœ‚ï¸ <b>Web Clipper ç»“æœ</b>\n\n"
        f"{medal} å¾—åˆ†ï¼š<b>{score:.1f}</b>\n"
        f"ğŸ“° <a href=\"{url}\">{title or url}</a>\n\n"
        f"ğŸ§  <i>{axiom or 'æ— å…¬ç†'}</i>\n\n"
        f"ğŸ’¬ {reason}\n\n"
        f"{inbox_line}"
    )
    send_message(text)


# â”€â”€ ä¸»å…¥å£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def clip_url(url: str, silent: bool = False) -> dict:
    """å®Œæ•´ Clip æµç¨‹ã€‚"""
    print(f"\nâœ‚ï¸  [Web Clipper] å¼€å§‹å¤„ç†: {url}")

    # Step 1: æå–æ­£æ–‡
    extracted = extract_content(url)
    title  = extracted["title"] or url
    text   = extracted["text"]
    author = extracted["author"]
    date   = extracted["date"]

    if not text:
        print("  âš ï¸  æ­£æ–‡æå–å¤±è´¥ï¼Œæ•ˆæœå—é™")

    # æ ‡é¢˜ fallback
    if not title or title == url:
        from urllib.parse import urlparse
        path  = urlparse(url).path.rstrip("/")
        slug  = path.split("/")[-1] if path else urlparse(url).netloc
        title = slug.replace("-", " ").replace("_", " ").title() or url

    print(f"  ğŸ“Œ æ ‡é¢˜: {title[:70]}")

    # Step 2: LLM è¯„åˆ†
    result = evaluate(title, text)

    if result is None:
        print(f"  âŒ è¯„åˆ†å¤±è´¥")
        if not silent:
            send_message(f"âœ‚ï¸ Web Clipper è¯„åˆ†å¤±è´¥\nğŸ”— {url}")
        return {"url": url, "title": title, "score": 0, "written": False, "filepath": ""}

    score  = float(result.get("score", 0))
    reason = result.get("reason", "")
    axiom  = result.get("axiom_extracted", "")

    print(f"  ğŸ“Š å¾—åˆ†: {score:.1f}")

    # Step 3: å†™å…¥ Inbox
    written  = False
    filepath = ""

    if score >= MIN_SCORE_INBOX:
        filepath = write_to_inbox(url, title, score, reason, axiom, author, date)
        written  = True

    # Step 4: é€šçŸ¥
    if not silent:
        notify(url, title, score, reason, axiom, written)

    return {
        "url":      url,
        "title":    title,
        "score":    score,
        "reason":   reason,
        "axiom":    axiom,
        "written":  written,
        "filepath": filepath,
    }


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Antigravity Web Clipper")
    parser.add_argument("url",        help="è¦å‰ªæŠ¥çš„ç½‘é¡µ URL")
    parser.add_argument("--silent",   action="store_true", help="ä¸æ¨é€ Telegram")
    parser.add_argument("--min-score", type=float, default=MIN_SCORE_INBOX)
    args   = parser.parse_args()

    MIN_SCORE_INBOX = args.min_score
    result = clip_url(args.url, silent=args.silent)
